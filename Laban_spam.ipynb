{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c11d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272041d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df = df.rename(columns={\"v1\":'label', \"v2\":'text'})\n",
    "print(df.head())\n",
    "label = df[\"label\"]\n",
    "texts = df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202261a",
   "metadata": {},
   "source": [
    "### To do: develop an accurate simple neural network model for spam classification (no LSTM, CNN, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c21988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Data is cleaned\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daad7254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of spam and ham labels \n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ff76c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the data by plotting\n",
    "sns.countplot(x=df['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb862b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will change the SMS label to binary values\n",
    "df['label'] = df['label'].map( {'spam': 1, 'ham': 0} )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6181446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham  = df[df['label'] == 0].copy()\n",
    "df_spam = df[df['label'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc6757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow keras libraries\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e8977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values#input\n",
    "y = df['label'].values#output\n",
    "#split the training and testing data, test size at 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118fd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175, 64, 23, 59, 1, 144, 1307, 24, 1308], [170, 315, 114, 32, 1011, 673, 14, 921, 599, 87, 67, 600, 2, 1143, 18, 776, 845, 91, 171, 270, 776, 1144, 1507, 674, 846, 847, 241]]\n"
     ]
    }
   ],
   "source": [
    "#prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)\n",
    "\n",
    "#integer encode the documents\n",
    "encoded_train = t.texts_to_sequences(X_train)\n",
    "encoded_test = t.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "print(encoded_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e02954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  64   23   59 ... 1307   24 1308]\n",
      " [ 270  776 1144 ...  846  847  241]\n",
      " [1821   86 3531 ...   77    3  778]\n",
      " ...\n",
      " [1191    2 1742 ...    9  119  326]\n",
      " [ 176    2    9 ...    3    8  783]\n",
      " [  27    3   85 ...    5  289  535]]\n"
     ]
    }
   ],
   "source": [
    "#document padding to a max length of 4 words\n",
    "max_length = 8\n",
    "train_pad = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "test_pad = pad_sequences(encoded_test, maxlen=max_length, padding='post')\n",
    "\n",
    "print(train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1ea460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 24)             178752    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               96500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               100200    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 395,653\n",
      "Trainable params: 395,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))#classification with 1 output\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c006a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/122 [==============================] - 2s 6ms/step - loss: 0.1961 - accuracy: 0.9215 - val_loss: 0.0836 - val_accuracy: 0.9773\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9862 - val_loss: 0.0689 - val_accuracy: 0.9809\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.0844 - val_accuracy: 0.9785\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1278 - val_accuracy: 0.9809\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1544 - val_accuracy: 0.9797\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.7100e-06 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9785\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4931e-08 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9803\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.0413e-09 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9791\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.0090e-09 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9785\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 6.9152e-10 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9785\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 5.4151e-10 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9785\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 4.5317e-10 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9785\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 3.9058e-10 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9779\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 3.4586e-10 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9779\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 3.1231e-10 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9779\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.9204e-10 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9779\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.7483e-10 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9785\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.6256e-10 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9785\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.5150e-10 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9785\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.3538e-10 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9785\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.2695e-10 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9785\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.2104e-10 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9785\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.1570e-10 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9785\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.1144e-10 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9785\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 2.0463e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9779\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 2.0017e-10 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9779\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.9552e-10 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9773\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.9172e-10 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.8577e-10 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9767\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.8265e-10 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9767\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.7813e-10 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9767\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.7597e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9773\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.7515e-10 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.7027e-10 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9773\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6662e-10 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9773\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6540e-10 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6434e-10 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9773\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6283e-10 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9773\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6117e-10 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.6059e-10 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9773\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5800e-10 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9773\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5842e-10 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9773\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5919e-10 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9773\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5867e-10 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9773\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5891e-10 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9773\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.6023e-10 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9773\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.6101e-10 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9773\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.6217e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9773\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5963e-10 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9773\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5400e-10 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9773\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5478e-10 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9773\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5567e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9773\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5556e-10 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5474e-10 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9773\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5185e-10 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9773\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5283e-10 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9773\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5353e-10 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9773\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5468e-10 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9773\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5549e-10 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9773\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5624e-10 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9773\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5721e-10 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9773\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5789e-10 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9779\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5815e-10 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9773\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5398e-10 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9779\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5510e-10 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9779\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5521e-10 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9779\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5416e-10 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9779\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5486e-10 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9779\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5578e-10 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9779\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5639e-10 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9779\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5702e-10 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9779\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5080e-10 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9779\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5151e-10 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9779\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 1.5229e-10 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9779\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5301e-10 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9779\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5369e-10 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9779\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5462e-10 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9779\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5525e-10 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9779\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5309e-10 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9779\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.4812e-10 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9779\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4874e-10 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9779\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4949e-10 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9779\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5018e-10 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9779\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5082e-10 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9779\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5144e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9779\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5068e-10 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9779\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4796e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9779\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4846e-10 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9779\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4915e-10 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9779\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4816e-10 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9779\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4787e-10 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9779\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.4842e-10 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9779\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4913e-10 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9779\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.4970e-10 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9779\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5040e-10 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9779\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5094e-10 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9779\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 1.5159e-10 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9779\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5209e-10 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9779\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5273e-10 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9779\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 1.5343e-10 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d0ebf5f40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(x=train_pad, y=y_train, epochs=100, validation_data=(test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30926071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2682678699493408, 0.9778708219528198]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model evaluation\n",
    "model.evaluate(test_pad, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab1dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv('output_spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a566219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ï»¿                                               text\n",
      "0     1  Feel Yourself That You Are Always Happy.. Slow...\n",
      "1     2  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
      "2     3                        Send me yetty's number pls.\n",
      "3     4  Hey so this sat are we going for the intro pil...\n",
      "4     5  I got it before the new year cos yetunde said ...\n",
      "5     6  Hey we can go jazz power yoga hip hop kb and y...\n",
      "6     7  Hey mate. Spoke to the mag people. Weâ°ÃÃ·re...\n",
      "7     8                             Morning only i can ok.\n",
      "8     9                               Wat time Ã_ finish?\n",
      "9    10              Shant disturb u anymore... Jia you...\n",
      "10   11  4mths half price Orange line rental & latest c...\n",
      "11   12  Your opinion about me? 1. Over 2. Jada 3. Kusr...\n",
      "12   13  MOON has come to color your dreams, STARS to m...\n",
      "13   14  You are a winner U have been specially selecte...\n",
      "14   15  Unless it's a situation where YOU GO GURL woul...\n",
      "15   16  Awww dat is sweet! We can think of something t...\n",
      "16   17                            Bring tat cd don forget\n",
      "17   18  Single line with a big meaning::::: \\Miss anyt...\n",
      "18   19     Jay's getting really impatient and belligerent\n",
      "19   20  Lol they were mad at first but then they woke ...\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a873ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: spam_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"spam_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b321da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spam_model/tokenizer.pkl', 'wb') as output:\n",
    "    pickle.dump(t, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be43ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = tf.keras.models.load_model(\"spam_model\")\n",
    "\n",
    "with open('spam_model/tokenizer.pkl', 'rb') as input:\n",
    "    tokener = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44841b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = test_pred['text']\n",
    "\n",
    "sms_notif = tokener.texts_to_sequences(sms)#converts text to numerical values before prediction\n",
    "sms_notif = pad_sequences(sms_notif, maxlen=max_length, padding='post')\n",
    "#PREDICTION\n",
    "pred = (model.predict(sms_notif) > 0.5).astype(\"int32\").flatten()#flatten to make a 1D arroy output prediction\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddce6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the prediction on a csv file\n",
    "Submission=pd.DataFrame(pred, columns=['Label']).to_csv('Laban_spam_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1f267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
